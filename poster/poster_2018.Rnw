\documentclass[portrait, a0paper]{tikzposter}
\usepackage{url}
\usepackage{booktabs}
\usepackage{adjustbox}
\usepackage{pdfpages}
\usepackage{xcolor}
\usepackage{dsfont}
\usepackage{verbatim}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{csquotes}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{enumerate}
\usepackage[absolute,overlay]{textpos}
\usepackage{psfrag}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{eqnarray}
\usepackage{arydshln}
\usepackage{tabularx}
\usepackage{placeins}
\usepackage{setspace}
\usepackage{colortbl}
\usepackage{mathtools}
\usepackage{wrapfig}
\usepackage{xargs}
\usepackage{subfig}

\definecolorpalette{BlueGrayOrange}{
    \definecolor{colorOne}{HTML}{C0C0C0}
    \definecolor{colorTwo}{HTML}{CCCCCC}
    \definecolor{colorThree}{HTML}{009440}
}
\usepackage{mathtools}
\usepackage{hyperref}
\usetheme{Desert}
\usecolorstyle[colorPalette=BlueGrayOrange]{Russia}
\usebackgroundstyle{Rays}
\title{Interpretable Machine Learning}
\author{Christoph Molnar \\ }
\institute{
LMU Munich / Department of Statistics/ \url{christoph.molnar@stat.uni-muenchen.de} \\
Prof. Dr. Bernd Bischl}
%\titlegraphic{\hspace{-3200px}\includegraphics[scale=0.3]{figures/logo.png}}
\usetitlestyle{Empty}
\colorlet{titlefgcolor}{black}
\colorlet{titlebgcolor}{colorOne}

<<setup-child, include = FALSE, echo=FALSE>>=
library(mlr)
library(ggplot2)
library(gridExtra)
library(data.table)
library(ggExtra)
library(knitr)

options(digits = 3, width = 65, str = strOptions(strict.width = "cut", vec.len = 3))

opts_chunk$set(
  echo        = FALSE,
  prompt      = FALSE,
  keep.source = TRUE,
  strip.white = TRUE,
  cache       = TRUE,
  tidy        = FALSE,
  concordance = TRUE,
  message     = FALSE,
  warning     = FALSE,

  size        = 'scriptsize',

  fig.height  = 5.8,
  fig.width   = 8,
  fig.pos     = "h!",
  small.mar   = TRUE,
  eps         = FALSE,
  crop        = TRUE,
  fig.align   = "center",
  out.width   = "0.4\\textwidth"
  # fig.path    = "knit-figure/prada1-"
)

theme_update(axis.line = element_line(colour = "black"),
  panel.grid.major = element_line(colour = "grey80"),
  panel.grid.minor = element_line(colour = "grey80"),
  panel.border = element_blank(),
  panel.background = element_rect(fill = "transparent"),
  plot.background = element_rect(fill = "transparent"))
@


\makeatletter
\renewcommand\section{%
   \@startsection
     {section}% name
     {1}% level
     {\z@}% indent
     {0ex \@plus -1ex \@minus -.2ex}% beforeskip, changed!
     {2.3ex \@plus.2ex}% afterskip
     {\normalfont\Large\bfseries}% style
}
\makeatother
\begin{document}
\SweaveOpts{concordance=TRUE}
\maketitle

\begin{columns}

\column{0.33}
\block{What did you learn, computer?}{
Let's predict how much rent you should pay for your flat, based on some data. [footnote]
We got some data on it, contains rent in Euros, the size of the living area, the location (inner city, outer ring, industry, party area).
TODO: Create graphic with features and output as icons.
We use machine learning methods to let the computer learn by itself to prediction. 
Machine learning is a set of techniques that lets the computer learn from data to make predictions. 
The good thing is, that we don't have to find out the exact relationship between the rent and the attributes of the flat, but the computer will. 
The bad thing is that the computer will not easily tell us the relationships it found out. 
Now we have the following problem:
TODO: Insert black box graphic

Except when you use methods from interpretable machine learning, which are presented in this poster. 
FOOTNOTE: the example is completely made up, don't use for actual life decisions.
}

\block{Interpretable Models}{
One approach: Just use machine learning models that only allow relationships with simple structures, like a decision tree, or a weighted sum of the inputs.
Advantage: Already interpretable
Disadvantage: Usually you pay with performance of the model.

\section*{Linear regression models}
\section*{Decision trees}
\section*{Decision rules}

All of the above techniques can also be used on a more meta level:
When you alread have a black box machine learning model, you can approximate it with an interpretable model.
TODO: Visualizaton.
}



\column{0.33}

\block{How do features affect the predictions?}{
\section*{Individual Conditional Expectation}
\section*{Partial Dependence Plots}
\section*{Average Accumulated Effects}
}


\column{0.33}
\block{Which features were important?}{
How important was a feature
}

\block{Why was this prediction made?}

\block{References}{
\begingroup
  \renewcommand{\section}[2]{}%
  \small
  \bibliographystyle{plain}
  \bibliography{Bib}
\endgroup
}
\end{columns}
\end{document}
