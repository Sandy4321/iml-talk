---
title: "Interpretable Machine Learning"
author: "Christoph Molnar"
date: "December 11, 2017"
output: ioslides_presentation
---

## 
Scenario: A company approaches you to predict data scientist salaries with machine learning.  

![](images/wow.jpg)


# Let's predict data scientist salaries



## What is Machine Learning

Machine learning is a method for teaching computers to make and improve predictions or behaviours based on data.


![](images/magic.jpg)


## Step 1: Find some data
Kaggle conducted an industry-wide survey of data scientists. 
Questions asked:  

- Demographic
- Salary
- Are you currently enrolled as a student at a degree granting school?	
- How adequately do you feel your title describes what you do (or what you did if retired)?	
- How long have you been learning data science?	

TODO: Add only relevant questions here for analysis


```{r load-data, warning=FALSE, include=FALSE}
library('mlr')
library('ggplot2')
library('tidyr')
library('lime')
source('code/prepare-kaggle-data.R')
```



## Step 2: Throw ML on your data
```{r learn, warning=FALSE}
set.seed(42)
task = makeRegrTask(data = survey.dat, target = 'CompensationAmount')
n = getTaskSize(task)
lrn = makeLearner('regr.randomForest', importance=TRUE)
mod = train(lrn, task, subset = seq(1, n, 2))
pred = predict(mod, task = task, subset = seq(2, n, 2))
## TODO: Find better variables https://www.kaggle.com/kaggle/kaggle-survey-2017/data
```
## Step 3: Profit. We are done! {.center}

```{r, echo=FALSE, out.width='70%', fig.align='center'}
knitr::include_graphics("images/done-here.gif")
```



## "There is a problem with the model!"
```{r, echo=FALSE, out.width='100%', fig.align='center'}
knitr::include_graphics("images/Hide-the-pain-harold-phone.jpg")
```


## "The older the applicants, the higher the predicted salary, regardless of skills."
```{r, echo=FALSE, out.width='100%', fig.align='center'}
knitr::include_graphics("images/age.jpeg")
```



# Individual Conditional Expectation

##

```{r}
ice = generatePartialDependenceData(mod, task, features ='Age', 
                                    individual = TRUE)
plotPartialDependence(ice) + scale_y_continuous(limits=c(0, NA))
```

## 

```{r}
ice.c = generatePartialDependenceData(mod, task, features ='Age', 
          individual = TRUE, center = list(Age=20))
plotPartialDependence(ice.c)
```


# Partial dependence plots

##

```{r}
pdp = generatePartialDependenceData(mod, task, features =c('Age'))
plotPartialDependence(pdp) + scale_y_continuous(limits=c(0, NA))
```


## "We want to understand the model better!"

# Permutation feature importance

##

```{r, warning=FALSE}
feat.imp = getFeatureImportance(mod, type=1)$res
dat = gather(feat.imp, key='Feature', value='Importance') %>% arrange(Importance)
dat$Feature = factor(dat$Feature, levels = dat$Feature)
ggplot(dat)  + geom_point(aes(y=Feature, x = Importance))
```

## Gender?!
```{r, echo=FALSE, fig.align='center', out.width='60%'}
knitr::include_graphics("images/big-mistake.png")
```

##

```{r}
pdp = generatePartialDependenceData(mod, task, features =c('GenderSelect'))
knitr::kable(pdp$data)
```

##

```{r, echo=FALSE, fig.align='center'}
knitr::include_graphics("images/hidden-pain-bias.jpg")
```



## "We want to understand each decision!"


# LIME

## 
```{r, echo=FALSE, fig.align='center'}
set.seed(44)
```
```{r, echo=TRUE, fig.align='center'}
dat = getTaskData(task)
explanation <- lime(dat, mod)
# Explain new instance
explainer <- lime::explain(dat[3, ], explanation, n_features = 3)
plot_features(explainer, ncol=1)
```



## Interpretability
- The degree to which an observer can understand the cause of a decision.
- Current state in machine learning: Minimize loss, get best prediction, ignore interpretation
- Current state in statistics: Fit model, interpret output, ignore predictive performance
- Ideal world: Get best predictive performance + interpretability

## When is it important
Interpretability of machine learning models is when the problem is fundamentally underspecified. 


## Book
Interested in learning more! 

Read my book about "Interpretable Machine Learning"
https://christophm.github.io/xai-book/

